<!DOCTYPE html><html><head>
        <link rel="stylesheet" type="text/css" href="./style.css">
    </head>
    <body>
        <div id="top-bar">
            <span class="banner" style="flex: 8;">MATH FRONTIER SEMINAR</span>
            <img id="logo" src="./RPI_Logo_Default.svg" alt="">
            <span class="banner" style="flex: 1;"></span>
        </div>

        <div id="flyer">
        
        <h1 id="title">Multi-objective Optimization: Applications in Modern Machine Learning Problems</h1>
        <div id="speaker-block"><img src="speaker_photos/hfernando.jpeg" id="speaker-photo" alt="photo of <a href=&quot;https://heshandevaka.github.io/&quot; target=&quot;_blank&quot;>Heshan Fernando</a>">
                <!-- <div id="speaker-image"></div> -->

                <div id="info-block">
                    <span id="speaker-name"><a href="https://heshandevaka.github.io/" target="_blank">Heshan Fernando</a></span>
                    <span id="affiliation"> RPI ECSE</span>

                    <div id="venue-block">
                        <table>
                            <tbody><tr><td>Time</td> <td>4:00 pm, <span id="date">11/03</span></td></tr>
                            <tr><td>Location</td> <td>Amos Eaton 216</td> </tr>
                            <tr><td>Food</td> <td id="food">Taiwanese food</td></tr>
                        </tbody></table>
                    </div>
                </div>
        </div>


        <div style="margin-top: 1em;">
            <h3 style="border-bottom: 4px solid black; padding-bottom:4pt;">Abstract</h3>
            <p id="abstract">This talk explores multi-objective optimization (MOO) as a principled framework for reconciling competing objectives in modern machine learning (ML). We present two case studies that demonstrate its effectiveness. First, we reformulate multi-modal learning (MML) as a MOO problem to address modality imbalance, proposing a gradient-based algorithm with theoretical convergence guarantees and up to 20Ã— computational savings, while outperforming existing MML methods empirically. Second, we examine LLM post-training, showing that the conventional sequential fine-tuning and preference optimization paradigm is theoretically suboptimal. We introduce a joint post-training framework that optimizes both objectives simultaneously, achieving up to 23% higher performance with minimal additional cost. Collectively, these studies illustrate how MOO principles promote greater balance, efficiency, and robustness in contemporary ML systems.</p>
        </div>

        <div id="bio-block">
            <h3>About the Speaker</h3>
            <p id="bio">Heshan Fernando is a 5th year PhD student in Department of Electrical, Computer, and Systems Engineering. His research interests lie in theory and applications of multi-objective optimization (MOO).</p>
        </div>
        </div>
        <div id="bottom">
            
        </div>
    
    

</body></html>